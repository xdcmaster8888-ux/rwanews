#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RWA News GitHub Pages è‡ªå‹•å…¬é–‹ã‚·ã‚¹ãƒ†ãƒ 
è¨˜äº‹è‡ªå‹•ç”Ÿæˆ â†’ HTML ç”Ÿæˆ â†’ GitHub Pages è‡ªå‹•ãƒ—ãƒƒã‚·ãƒ¥
"""

import os
import json
import subprocess
import sys
import logging
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

load_dotenv()

DOCS_DIR = Path('docs')
DATA_DIR = DOCS_DIR / 'data'
ARTICLES_DIR = Path('output')

def ensure_directories():
    """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    DOCS_DIR.mkdir(exist_ok=True)
    DATA_DIR.mkdir(exist_ok=True)
    logger.info('âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèªå®Œäº†')

def collect_articles():
    """è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†"""
    logger.info('\nã€ã‚¹ãƒ†ãƒƒãƒ— 1ã€‘è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«åé›†')
    logger.info('=' * 60)

    articles = []
    article_files = sorted(ARTICLES_DIR.glob('rwa_news_*.txt'), reverse=True)

    for article_file in article_files[:20]:  # æœ€æ–°20è¨˜äº‹
        try:
            with open(article_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            filename = article_file.stem
            timestamp = filename.replace('rwa_news_', '')

            # æ—¥æ™‚è§£æ
            try:
                dt = datetime.strptime(timestamp, '%Y%m%d_%H%M%S')
                date_str = dt.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
            except:
                date_str = timestamp

            # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡ºï¼ˆæœ€åˆã®è¡Œï¼‰
            lines = content.split('\n')
            title = lines[0].replace('ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘', '').strip() if lines else 'Untitled'

            articles.append({
                'id': filename,
                'title': title,
                'timestamp': timestamp,
                'date': date_str,
                'content': content[:500],  # æœ€åˆã®500æ–‡å­—
                'url': f'article/{filename}.html'
            })

            logger.info(f'  âœ… {date_str} - {title[:50]}')

        except Exception as e:
            logger.warning(f'  âŒ {article_file.name}: {str(e)[:50]}')

    logger.info(f'\nâœ… {len(articles)} ä»¶ã®è¨˜äº‹ã‚’åé›†\n')
    return articles

def generate_articles_json(articles):
    """articles.json ã‚’ç”Ÿæˆ"""
    logger.info('ã€ã‚¹ãƒ†ãƒƒãƒ— 2ã€‘JSON ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ')
    logger.info('=' * 60)

    json_file = DATA_DIR / 'articles.json'

    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump({
            'generated_at': datetime.now().isoformat(),
            'total_articles': len(articles),
            'articles': articles
        }, f, ensure_ascii=False, indent=2)

    logger.info(f'âœ… JSON ç”Ÿæˆ: {json_file}')
    logger.info(f'   è¨˜äº‹æ•°: {len(articles)} ä»¶\n')

def generate_article_pages(articles):
    """å€‹åˆ¥è¨˜äº‹ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    logger.info('ã€ã‚¹ãƒ†ãƒƒãƒ— 3ã€‘è¨˜äº‹ãƒšãƒ¼ã‚¸ HTML ç”Ÿæˆ')
    logger.info('=' * 60)

    articles_dir = DOCS_DIR / 'article'
    articles_dir.mkdir(exist_ok=True)

    for article in articles[:10]:  # æœ€æ–°10è¨˜äº‹ã®ã¿ãƒšãƒ¼ã‚¸åŒ–
        try:
            # è¨˜äº‹æœ¬æ–‡ã‚’èª­ã¿è¾¼ã¿
            article_file = ARTICLES_DIR / f'{article["id"]}.txt'
            if not article_file.exists():
                continue

            with open(article_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # HTML ãƒšãƒ¼ã‚¸ç”Ÿæˆ
            html_content = f'''<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{article['title']}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }}
        .container {{ max-width: 800px; margin: 0 auto; }}
        article {{
            background: white;
            border-radius: 10px;
            padding: 40px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            line-height: 1.8;
        }}
        article h1 {{ color: #667eea; margin-bottom: 10px; }}
        .meta {{ color: #999; font-size: 0.9em; margin-bottom: 30px; }}
        pre {{ background: #f5f5f5; padding: 15px; border-radius: 5px; overflow-x: auto; }}
        a.back {{ color: #667eea; text-decoration: none; margin-top: 30px; display: block; }}
    </style>
</head>
<body>
    <div class="container">
        <article>
            <h1>{article['title']}</h1>
            <div class="meta">ğŸ“… {article['date']}</div>
            <pre>{content}</pre>
            <a href="../index.html" class="back">â† ãƒ›ãƒ¼ãƒ ã«æˆ»ã‚‹</a>
        </article>
    </div>
</body>
</html>'''

            # HTML ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            html_file = articles_dir / f'{article["id"]}.html'
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)

            logger.info(f'  âœ… {article["date"]}')

        except Exception as e:
            logger.warning(f'  âŒ {article["id"]}: {str(e)[:50]}')

    logger.info(f'\nâœ… è¨˜äº‹ãƒšãƒ¼ã‚¸ç”Ÿæˆå®Œäº†\n')

def update_index_html(articles):
    """index.html ã‚’æ›´æ–°ã—ã¦æœ€æ–°è¨˜äº‹ã‚’è¡¨ç¤º"""
    logger.info('ã€ã‚¹ãƒ†ãƒƒãƒ— 4ã€‘ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°')
    logger.info('=' * 60)

    articles_html = '\n'.join([
        f'''        <div class="article-item">
            <h3><a href="{article['url']}">{article['title']}</a></h3>
            <time>ğŸ“… {article['date']}</time>
            <p>{article['content'][:150]}...</p>
        </div>'''
        for article in articles[:15]
    ])

    index_file = DOCS_DIR / 'index.html'

    if index_file.exists():
        with open(index_file, 'r', encoding='utf-8') as f:
            html = f.read()

        # å‹•çš„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°
        import re
        html = re.sub(
            r'<!-- ARTICLES_START -->.*?<!-- ARTICLES_END -->',
            f'<!-- ARTICLES_START -->\n{articles_html}\n    <!-- ARTICLES_END -->',
            html,
            flags=re.DOTALL
        )

        with open(index_file, 'w', encoding='utf-8') as f:
            f.write(html)

        logger.info(f'âœ… index.html æ›´æ–°')
    else:
        logger.warning(f'âš ï¸  index.html ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')

    logger.info(f'   æœ€æ–°è¨˜äº‹: {len(articles)} ä»¶\n')

def git_commit_and_push():
    """Git ã‚³ãƒŸãƒƒãƒˆï¼†ãƒ—ãƒƒã‚·ãƒ¥"""
    logger.info('ã€ã‚¹ãƒ†ãƒƒãƒ— 5ã€‘GitHub ã¸ãƒ—ãƒƒã‚·ãƒ¥')
    logger.info('=' * 60)

    try:
        # ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°
        logger.info('ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°...')
        subprocess.run(['git', 'add', 'docs/', '.'], cwd=Path.cwd(), check=True, capture_output=True)

        # ã‚³ãƒŸãƒƒãƒˆ
        commit_msg = f'ğŸš€ RWA News Auto-Publish: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
        logger.info(f'ğŸ’¾ ã‚³ãƒŸãƒƒãƒˆ: {commit_msg}')
        result = subprocess.run(
            ['git', 'commit', '-m', commit_msg],
            cwd=Path.cwd(),
            capture_output=True,
            text=True
        )

        if result.returncode == 0:
            logger.info('âœ… ã‚³ãƒŸãƒƒãƒˆæˆåŠŸ')
        elif 'nothing to commit' in result.stdout.lower():
            logger.info('â„¹ï¸  å¤‰æ›´ãŒã‚ã‚Šã¾ã›ã‚“')
        else:
            logger.warning(f'âš ï¸  ã‚³ãƒŸãƒƒãƒˆè­¦å‘Š: {result.stdout[:100]}')

        # ãƒ—ãƒƒã‚·ãƒ¥
        logger.info('ğŸŒ GitHub ã¸ãƒ—ãƒƒã‚·ãƒ¥...')
        result = subprocess.run(
            ['git', 'push', 'origin', 'main'],
            cwd=Path.cwd(),
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0:
            logger.info('âœ… GitHub ãƒ—ãƒƒã‚·ãƒ¥æˆåŠŸï¼')
            logger.info('ğŸ“± URL: https://github.com/[username]/rwanews/tree/main/docs')
        else:
            logger.error(f'âŒ ãƒ—ãƒƒã‚·ãƒ¥å¤±æ•—: {result.stderr[:200]}')

        logger.info()

    except subprocess.TimeoutExpired:
        logger.error('âŒ ãƒ—ãƒƒã‚·ãƒ¥ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ')
    except Exception as e:
        logger.error(f'âŒ Git å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}')

def main():
    logger.info('\n' + '=' * 60)
    logger.info('ğŸš€ RWA News GitHub Pages è‡ªå‹•å…¬é–‹')
    logger.info('=' * 60)

    # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
    ensure_directories()
    articles = collect_articles()

    if not articles:
        logger.error('âŒ è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        return False

    generate_articles_json(articles)
    generate_article_pages(articles)
    update_index_html(articles)
    git_commit_and_push()

    logger.info('=' * 60)
    logger.info('âœ… GitHub Pages å…¬é–‹å®Œäº†ï¼')
    logger.info('=' * 60)
    logger.info('\nğŸ“¡ ã‚µã‚¤ãƒˆ URL:')
    logger.info('  https://[username].github.io/rwanews/')
    logger.info('\nğŸ’¡ è¨­å®šæ–¹æ³•:')
    logger.info('  1. GitHub ãƒªãƒã‚¸ãƒˆãƒªã® Settings â†’ Pages')
    logger.info('  2. Source: main branch /docs folder')
    logger.info('  3. æ•°åˆ†ã§è‡ªå‹•å…¬é–‹ã•ã‚Œã¾ã™\n')

    return True

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
