#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RWAç‰¹åŒ–å‹æŠ•è³‡ãƒ‹ãƒ¥ãƒ¼ã‚¹è‡ªå‹•å…¬é–‹ã‚·ã‚¹ãƒ†ãƒ ï¼ˆv4.0 - GitHub Pagesç‰ˆï¼‰
Google Trends + AIç”Ÿæˆ + ç”»åƒç”Ÿæˆ + GitHub Pagesè‡ªå‹•å…¬é–‹
åŸ·ç­†è€…: xdc.masterï¼ˆä¸å‹•ç”£é‹å–¶ Ã— XDCé•·æœŸä¿æœ‰ã‚¤ãƒ³ãƒ™ã‚¹ã‚¿ãƒ¼ï¼‰

ã€æ©Ÿèƒ½ã€‘
- Google Trends ã«ã‚ˆã‚‹RWAé–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—
- ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®è©³ç´°è¨˜äº‹ç”Ÿæˆï¼ˆ1,200-1,500æ–‡å­—ï¼‰
- ç”»åƒç”Ÿæˆï¼ˆ3æšï¼šå†’é ­ãƒ»ä¸­ç›¤ãƒ»çµ‚ç›¤ï¼‰
- HTML ãƒšãƒ¼ã‚¸è‡ªå‹•ç”Ÿæˆï¼ˆã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³å¯¾å¿œï¼‰
- GitHub Pages è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤
"""

import os
import json
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
import logging
import requests
import random

# Google Trends ã¨ AI ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from pytrends.request import TrendReq
import google.generativeai as genai

# ç”»åƒç”Ÿæˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from PIL import Image, ImageDraw, ImageFont

# SNSåˆ†æãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import tweepy
except ImportError:
    tweepy = None

try:
    from nltk.sentiment import SentimentIntensityAnalyzer
    import nltk
    nltk.download('vader_lexicon', quiet=True)
except ImportError:
    SentimentIntensityAnalyzer = None

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒã‚¹ã‚¿ãƒ¼è¨­å®šï¼ˆãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ™ãƒ¼ã‚¹ï¼‰
try:
    import config
except ImportError:
    logger.warning('config.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™')
    config = None

# ãƒã‚¯ãƒ­æ–‡è„ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆæ­´å²çš„èƒŒæ™¯ã®ç†è§£ï¼‰
try:
    import rwa_context
except ImportError:
    logger.warning('rwa_context.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒã‚¯ãƒ­æ–‡è„ˆã¯ä½¿ç”¨ã—ã¾ã›ã‚“')
    rwa_context = None

# RWAé–¢é€£ãƒ¯ãƒ¼ãƒ‰ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ç”¨ï¼‰
RWA_KEYWORDS = [
    'Ondo', 'PAXG', 'RWA', 'tokenized assets',
    'real world assets', 'MKR', 'USDe',
    'ä¸å‹•ç”£ãƒˆãƒ¼ã‚¯ãƒ³', 'å®Ÿç‰©è³‡ç”£ãƒˆãƒ¼ã‚¯ãƒ³åŒ–'
]

# RWAé–¢é€£ã®ä¸»è¦ã‚½ãƒ¼ã‚¹ï¼ˆå‚ç…§å…ƒï¼‰
EVIDENCE_SOURCES = [
    {'name': 'Coin Telegraph', 'url': 'https://cointelegraph.jp', 'category': 'ãƒ‹ãƒ¥ãƒ¼ã‚¹'},
    {'name': 'The Block', 'url': 'https://www.theblock.co', 'category': 'ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³åˆ†æ'},
    {'name': 'CoinDesk', 'url': 'https://www.coindesk.com', 'category': 'ãƒ‹ãƒ¥ãƒ¼ã‚¹'},
    {'name': 'Messari', 'url': 'https://messari.io', 'category': 'ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹'},
    {'name': 'Glassnode', 'url': 'https://glassnode.com', 'category': 'ã‚ªãƒ³ãƒã‚§ãƒ¼ãƒ³åˆ†æ'},
    {'name': 'Token Terminal', 'url': 'https://tokenterminal.com', 'category': 'ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³åˆ†æ'},
    {'name': 'Chainlink', 'url': 'https://chain.link/ja', 'category': 'ã‚ªãƒ©ã‚¯ãƒ«'},
    {'name': 'é‡‘èåº - ä»®æƒ³è³‡ç”£é–¢é€£æ”¿ç­–', 'url': 'https://www.fsa.go.jp', 'category': 'è¦åˆ¶'},
    {'name': 'OpenZeppelin', 'url': 'https://docs.openzeppelin.com', 'category': 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»'},
    {'name': 'Aave ãƒ—ãƒ­ãƒˆã‚³ãƒ«', 'url': 'https://aave.com/ja', 'category': 'DeFi'}
]


class RWANewsGenerator:
    """RWAæŠ•è³‡ãƒ‹ãƒ¥ãƒ¼ã‚¹è‡ªå‹•ç”Ÿæˆãƒ»GitHub Pageså…¬é–‹ã‚·ã‚¹ãƒ†ãƒ ï¼ˆv4.0ï¼‰"""

    def __init__(self):
        self.api_key = os.getenv('GOOGLE_API_KEY')
        self.nanobanana_key = os.getenv('NANOBANANA_API_KEY', '')
        self.twitter_bearer_token = os.getenv('TWITTER_BEARER_TOKEN', '')

        if not self.api_key:
            raise ValueError('GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')

        genai.configure(api_key=self.api_key)

        # VADER Sentiment Analyzer ã‚’åˆæœŸåŒ–
        if SentimentIntensityAnalyzer:
            self.sentiment_analyzer = SentimentIntensityAnalyzer()
        else:
            self.sentiment_analyzer = None

        logger.info('èªè¨¼æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸ')

    async def fetch_trends(self) -> dict:
        """Google Trendsã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            logger.info('Google Trendsã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...')
            pytrends = TrendReq(hl='ja-JP', tz=540)

            trends_data = {}
            for keyword in RWA_KEYWORDS:
                try:
                    pytrends.build_payload(
                        kw_list=[keyword],
                        timeframe='now 7-d',
                        geo='JP'
                    )
                    interest_overtime = pytrends.interest_over_time()

                    if not interest_overtime.empty:
                        trend_score = int(interest_overtime.iloc[-1, 0])
                        trends_data[keyword] = trend_score
                        logger.info(f'{keyword}: ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¹ã‚³ã‚¢ {trend_score}')
                except Exception as e:
                    logger.warning(f'{keyword}: ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—å¤±æ•— - {str(e)[:50]}')
                    trends_data[keyword] = 0

            return trends_data

        except Exception as e:
            logger.warning(f'Google Trends å…¨ä½“ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}')
            return {kw: 0 for kw in RWA_KEYWORDS}

    async def fetch_coingecko_data(self) -> dict:
        """CoinGecko API ã‹ã‚‰ä»®æƒ³è³‡ç”£ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            logger.info('CoinGecko ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...')
            response = requests.get(
                'https://api.coingecko.com/api/v3/simple/price',
                params={
                    'ids': 'ondo,xdc-network,mantle,aave,curve-dao-token',
                    'vs_currencies': 'jpy,usd',
                    'include_market_cap': 'true',
                    'include_24hr_vol': 'true',
                    'include_24hr_change': 'true'
                },
                timeout=10
            )

            if response.status_code == 200:
                data = response.json()
                logger.info('âœ… CoinGecko ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ')
                return data
            else:
                logger.warning(f'CoinGecko ã‚¨ãƒ©ãƒ¼: {response.status_code}')
                return {}

        except Exception as e:
            logger.warning(f'CoinGecko å–å¾—å¤±æ•—: {str(e)[:50]}')
            return {}

    def generate_gradient_image(self, width: int = 1024, height: int = 576,
                               title: str = "RWA News") -> str:
        """ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³èƒŒæ™¯ã®ç”»åƒã‚’ç”Ÿæˆ"""
        try:
            img = Image.new('RGB', (width, height), color='white')
            draw = ImageDraw.Draw(img)

            # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³èƒŒæ™¯
            for y in range(height):
                ratio = y / height
                r = int(102 + (118 - 102) * ratio)
                g = int(126 + (75 - 126) * ratio)
                b = int(234 + (186 - 234) * ratio)
                draw.line([(0, y), (width, y)], fill=(r, g, b))

            # ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ 
            try:
                font = ImageFont.truetype("C:/Windows/Fonts/arial.ttf", 48)
            except:
                font = ImageFont.load_default()

            text_bbox = draw.textbbox((0, 0), title, font=font)
            text_width = text_bbox[2] - text_bbox[0]
            text_height = text_bbox[3] - text_bbox[1]
            x = (width - text_width) // 2
            y = (height - text_height) // 2

            draw.text((x, y), title, fill='white', font=font)

            # ä¿å­˜
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_dir = Path('output')
            output_dir.mkdir(exist_ok=True)
            filename = output_dir / f'rwa_image_{timestamp}.png'
            img.save(filename)

            logger.info(f'ç”»åƒç”Ÿæˆ: {filename}')
            return str(filename)

        except Exception as e:
            logger.warning(f'ç”»åƒç”Ÿæˆå¤±æ•—: {str(e)}')
            return None

    def generate_news_article(self, trends_data: dict) -> str:
        """ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚º + ãƒã‚¯ãƒ­æ–‡è„ˆ + ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±ãƒ™ãƒ¼ã‚¹ã® RWA ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ç”Ÿæˆ"""
        try:
            logger.info('ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚º + ãƒã‚¯ãƒ­æ–‡è„ˆ + ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±ã§è¨˜äº‹ã‚’ç”Ÿæˆä¸­...')

            # config.py ã‹ã‚‰ RWA ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—
            fundamentals_context = self._build_fundamentals_context()

            # rwa_context.py ã‹ã‚‰ ãƒã‚¯ãƒ­æ–‡è„ˆã‚’å–å¾—
            macro_context = self._build_macro_context()

            # ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢
            top_tier_news = self._search_top_tier_news('RWA market news')

            # ãƒ‹ãƒ¥ãƒ¼ã‚¹ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æ•´å½¢
            news_snippets_text = "\n".join([f"  - {snippet}" for snippet in top_tier_news.get('snippets', [])])

            prompt = f"""
            ã€RWAï¼ˆReal World Assetsï¼‰ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚º + ãƒã‚¯ãƒ­æ–‡è„ˆåˆ†æè¨˜äº‹ã®ç”Ÿæˆã€‘

            ã€æœ¬æ—¥ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã€‘
            {json.dumps(trends_data, ensure_ascii=False, indent=2)}

            ã€RWAå¸‚å ´ã®æ§‹é€ çš„èƒŒæ™¯æƒ…å ±ã€‘
            {fundamentals_context}

            ã€RWAå¸‚å ´ã®æ­´å²çš„ãƒã‚¯ãƒ­æ–‡è„ˆã€‘
            {macro_context}

            ã€æœ¬æ—¥ã®ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±ï¼ˆå³é¸ã‚½ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‘
            ä»¥ä¸‹ã¯ã€{', '.join(top_tier_news.get('domains', [])[:3])} ãªã©ã®ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰æŠ½å‡ºã—ãŸä¿¡é ¼åº¦ã®é«˜ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»åˆ†æã§ã™ã€‚
            SEOã‚¹ãƒ‘ãƒ ã‚„ä½å“è³ªã‚µã‚¤ãƒˆã¯å®Œå…¨ã«é™¤å¤–ã—ã¦ã„ã¾ã™ï¼š
{news_snippets_text}

            åŸ·ç­†è€…: xdc.masterï¼ˆä¸å‹•ç”£é‹å–¶è€…ãƒ»é•·æœŸã‚¤ãƒ³ãƒ™ã‚¹ã‚¿ãƒ¼è¦–ç‚¹ï¼‰

            ä»¥ä¸‹ã®å½¢å¼ã§ã€RWAã‚»ã‚¯ã‚¿ãƒ¼ã®ã€å®Ÿéœ€ã€‘ã¨ã€ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã€‘ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸæ·±ã„åˆ†æè¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

            ã€é‡è¦ãªæŒ‡ç¤ºã€‘
            - ã“ã‚Œã¯ä¾¡æ ¼é¨°è½äºˆæ¸¬ã§ã¯ãªãã€æ¥­ç•Œå‹•å‘ãƒ»åˆ¶åº¦æ•´å‚™ãƒ»æ©Ÿé–¢å‚å…¥ãƒ»è¦åˆ¶ã‚¯ãƒªã‚¢ã«åŸºã¥ãåˆ†æã§ã™
            - ä¸Šè¨˜ã®ã€Œæ­´å²çš„ãƒã‚¯ãƒ­æ–‡è„ˆã€ã¨æœ¬æ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’é–¢é€£ä»˜ã‘ã¦ã€ã€ãªãœä»Šã“ã®å‹•ããŒèµ·ãã¦ã„ã‚‹ã®ã‹ã€ã€èƒŒæ™¯ã«ä½•ãŒã‚ã‚‹ã®ã‹ã€ã‚’æ·±ãèª¬æ˜ã—ã¦ãã ã•ã„
            - ä¾‹ï¼šã€XDCã®å–å¼•é«˜ãŒå¢—åŠ ã€ã¨ã„ã†æ—¥ã€…ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã‚‰ã€ã€XDC Network ã® ICCï¼ˆå›½éš›å•†æ¥­ä¼šè­°æ‰€ï¼‰ã¨ã®ææºã«ã‚ˆã‚Šã€è²¿æ˜“é‡‘èã®ã‚ªãƒ³ãƒã‚§ãƒ¼ãƒ³åŒ–ãŒå®Ÿç¾ã—ã¤ã¤ã‚ã‚‹ã‹ã‚‰ã“ãã€æ©Ÿé–¢æŠ•è³‡å®¶ãŒè³‡é‡‘ã‚’æµå…¥ã•ã›ã¦ã„ã‚‹ã€ã¨ã„ã†ã‚ˆã†ã«æ·±ã„è€ƒå¯Ÿï¼ˆWhyï¼‰ã‚’è¨˜è¿°
            - **ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±ã®æ´»ç”¨**: ä¸Šè¨˜ã®ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ãƒ¡ãƒ‡ã‚£ã‚¢ï¼ˆBloombergã€CoinDeskã€The Blockã€Messariç­‰ï¼‰ã‹ã‚‰æŠ½å‡ºã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»åˆ†æã‚’å‚è€ƒã«ã€è¨˜äº‹ã«å…·ä½“çš„ãªäº‹ä¾‹ã‚„çµ±è¨ˆæ•°å­—ã‚’å«ã‚ã‚‹
            - **ä¿¡é ¼æ€§ã¨æ ¹æ‹ **: å€‹äººãƒ–ãƒ­ã‚°ã‚„ã¾ã¨ã‚ã‚µã‚¤ãƒˆã§ã¯ãªãã€ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ã‚½ãƒ¼ã‚¹ã®ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’åŸºã«åŸ·ç­†ã™ã‚‹ãŸã‚ã€ã‚ˆã‚Šèª¬å¾—åŠ›ã®ã‚ã‚‹è¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„

            ã€è¨˜äº‹æ§‹æˆã€‘
            1. **å†’é ­** - æœ¬æ—¥ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ã€ãã®èƒŒæ™¯ã«ã‚ã‚‹ãƒã‚¯ãƒ­çš„ãªæ–‡è„ˆ
            2. **æ©Ÿé–¢æŠ•è³‡å®¶å‚å…¥ã®é€²æ—** - BlackRockã€Franklin Templeton ãªã©ã®å‹•ãï¼ˆå…·ä½“ä¾‹ã‚’ç¤ºã™ï¼‰
            3. **è¦åˆ¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æ•´å‚™çŠ¶æ³** - SECã€é‡‘èåºã€FCAãªã©ã®æœ€æ–°ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
            4. **æŠ€è¡“ãƒ»ã‚¤ãƒ³ãƒ•ãƒ©ã®é€²åŒ–** - ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ç›¸äº’é‹ç”¨æ€§
            5. **ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ææºã¨å®Ÿéœ€ã®å½¢æˆ** - TradFi ã¨ã®çµ±åˆã€å¤§æ‰‹æ©Ÿé–¢ã¨ã®å”æ¥­ï¼ˆãªãœã“ã‚ŒãŒé‡è¦ã‹èª¬æ˜ï¼‰
            6. **ä¸»è¦ãªRWAãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç¾¤** - å³é¸50éŠ˜æŸ„ã®åˆ†é¡åˆ¥ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
            7. **é•·æœŸæŠ•è³‡å®¶å‘ã‘ã®è¦–ç‚¹** - ä¾¡æ ¼æŠ•æ©Ÿã§ã¯ãªãå®Ÿéœ€ãƒ™ãƒ¼ã‚¹ã®åˆ¤æ–­è»¸
            8. **çµè«–** - RWAã‚»ã‚¯ã‚¿ãƒ¼ã¸ã®æ§‹é€ çš„ãªè¦‹ç«‹ã¦

            ã€åˆ¶ç´„ã€‘
            - 1,800ï½2,200æ–‡å­—ç¨‹åº¦
            - æ—¥æœ¬èª
            - ä¾¡æ ¼äºˆæ¸¬ã‚„ã€ç…½ã‚Šã€è¡¨ç¾ã¯é¿ã‘ã€äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã®åˆ†æ
            - ONDOã€XDCã€LINKã€Chainlinkã€MakerDAOã€Centrifuge ãªã©å®Ÿåœ¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å…·ä½“ä¾‹ã¨ã—ã¦å«ã‚ã‚‹
            - æ©Ÿé–¢æŠ•è³‡å®¶ãƒ»é•·æœŸæŠ•è³‡å®¶å‘ã‘ã®å°‚é–€çš„ã‹ã¤å†·é™ãªå†…å®¹
            - ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚º5è»¸ï¼ˆæ©Ÿé–¢æŠ•è³‡å®¶å‚å…¥ã€è¦åˆ¶ã€æŠ€è¡“ã€ææºã€å¸‚å ´å‹•å‘ï¼‰ã‚’ç¹”ã‚Šè¾¼ã‚€
            - æ­´å²çš„ãªèƒŒæ™¯ï¼ˆä¸Šè¨˜ãƒã‚¯ãƒ­æ–‡è„ˆï¼‰ã¨ã®é–¢é€£æ€§ã‚’ç¤ºã™è¨˜è¿°ã‚’å«ã‚ã‚‹
            """

            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(prompt)

            if response.text:
                logger.info('âœ… ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚º + ãƒã‚¯ãƒ­æ–‡è„ˆ + ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±ãƒ™ãƒ¼ã‚¹è¨˜äº‹ç”Ÿæˆå®Œäº†')
                return response.text
            else:
                logger.error('AI å¿œç­”ãŒç©ºã§ã™')
                return self._get_default_article()

        except Exception as e:
            logger.error(f'AI è¨˜äº‹ç”Ÿæˆå¤±æ•—: {str(e)}')
            return self._get_default_article()

    def _build_fundamentals_context(self) -> str:
        """config.py ã‹ã‚‰ RWA ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰"""
        if not config:
            return ""

        context_parts = []

        # RWAå³é¸50éŠ˜æŸ„ã®æ¦‚è¦
        context_parts.append("ã€RWAå³é¸50éŠ˜æŸ„ã®åˆ†å¸ƒã€‘")
        for category, tokens in config.RWA_TOKENS.items():
            token_names = ", ".join([t['symbol'] for t in tokens])
            context_parts.append(f"  - {category}: {token_names}")

        # ã‚­ãƒ¼ãƒ‘ãƒ¼ã‚½ãƒ³ã®æœ€æ–°å‹•å‘ä¾‹
        context_parts.append("\nã€æ¥­ç•Œã‚­ãƒ¼ãƒ‘ãƒ¼ã‚½ãƒ³30åã€‘")
        if len(config.KEY_FIGURES) >= 5:
            context_parts.append("  ä¸»è¦äººç‰©ï¼ˆæŠœç²‹ï¼‰:")
            for person in config.KEY_FIGURES[:5]:
                context_parts.append(f"    - {person['name']} ({person['affiliation']}): {person['recent_focus']}")

        # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è»¸
        context_parts.append("\nã€ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°5è»¸ã€‘")
        for category, data in config.FUNDAMENTALS_CATEGORIES.items():
            weight_pct = data['weight'] * 100
            indicators = data['indicators'][:2]  # æœ€åˆã®2ã¤ã®ã¿è¡¨ç¤º
            context_parts.append(f"  - {category} ({weight_pct}%): {', '.join(indicators)}")

        # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚«ãƒ†ã‚´ãƒª
        context_parts.append("\nã€ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†é¡ã‚«ãƒ†ã‚´ãƒªã€‘")
        categories = ", ".join(config.NEWS_CATEGORIES[:6])
        context_parts.append(f"  {categories}...")

        # ä¿¡é ¼åº¦ã‚½ãƒ¼ã‚¹
        context_parts.append("\nã€ä¿¡é ¼åº¦ã®é«˜ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ã€‘")
        high_sources = config.CREDIBILITY_SOURCES['è¶…é«˜'][:3]
        context_parts.append(f"  è¶…é«˜: {', '.join(high_sources)}")

        return "\n".join(context_parts)

    def _generate_advanced_search_query(self, keyword: str, num_domains: int = 4) -> tuple:
        """é«˜åº¦ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆï¼šã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã¿ã‚’å¯¾è±¡ã«"""
        try:
            if not config or not hasattr(config, 'TARGET_DOMAINS'):
                logger.warning('TARGET_DOMAINS ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
                return None, []

            import random

            # ãƒ©ãƒ³ãƒ€ãƒ ã« 3ï½5 å€‹ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’é¸æŠ
            selected_domains = random.sample(
                config.TARGET_DOMAINS,
                min(num_domains, len(config.TARGET_DOMAINS))
            )

            # site: æ¼”ç®—å­ã‚’ä½¿ã£ãŸæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
            site_filters = " OR ".join([f"site:{domain}" for domain in selected_domains])
            advanced_query = f'"{keyword}" RWA ({site_filters})'

            logger.info(f'æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ: {advanced_query}')
            return advanced_query, selected_domains

        except Exception as e:
            logger.warning(f'æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆå¤±æ•—: {str(e)}')
            return None, []

    def _search_top_tier_news(self, keyword: str) -> dict:
        """ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢"""
        try:
            logger.info(f'ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰æ¤œç´¢ä¸­: {keyword}')

            # é«˜åº¦ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
            search_query, selected_domains = self._generate_advanced_search_query(keyword)

            if not search_query:
                logger.warning('æ¤œç´¢ã‚¯ã‚¨ãƒªãŒç”Ÿæˆã§ãã¾ã›ã‚“')
                return self._get_demo_news_data()

            # Google Custom Search API ã¾ãŸã¯ requests + BeautifulSoup ã§æ¤œç´¢
            # ã“ã“ã§ã¯ã€ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™ï¼ˆå®Ÿè£…æ™‚ã¯å®Ÿéš›ã®æ¤œç´¢APIã‚’ä½¿ç”¨ï¼‰
            try:
                response = requests.get(
                    'https://www.google.com/search',
                    params={'q': search_query},
                    headers={
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    },
                    timeout=10
                )

                # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã‹ã‚‰ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
                # å®Ÿè£…ä¸Šã¯Google Custom Search APIæ¨å¥¨
                search_results = {
                    'query': search_query,
                    'domains': selected_domains,
                    'snippets': self._extract_snippets_from_search(response.text, selected_domains),
                    'status': 'success'
                }

                logger.info(f'æ¤œç´¢å®Œäº†: {len(search_results["snippets"])} ä»¶ã®ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢è¨˜äº‹ã‚’æŠ½å‡º')
                return search_results

            except Exception as search_error:
                logger.warning(f'Google æ¤œç´¢å¤±æ•—: {str(search_error)[:100]}')
                return self._get_demo_news_data()

        except Exception as e:
            logger.error(f'ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢å¤±æ•—: {str(e)}')
            return self._get_demo_news_data()

    def _extract_snippets_from_search(self, html_content: str, domains: list) -> list:
        """æ¤œç´¢çµæœã‹ã‚‰ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æŠ½å‡ºï¼ˆå®Ÿè£…ã¯ç°¡æ˜“ç‰ˆï¼‰"""
        try:
            # å®Ÿè£…ä¾‹ï¼šBeautifulSoup ã‚’ä½¿ç”¨
            # from bs4 import BeautifulSoup
            # soup = BeautifulSoup(html_content, 'html.parser')
            # snippets = []
            # for snippet in soup.find_all('span', class_='st'):
            #     text = snippet.get_text()
            #     snippets.append(text)
            # return snippets[:5]  # æœ€å¤§5ä»¶

            # ã“ã“ã§ã¯ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
            logger.info('ã‚¹ãƒ‹ãƒšãƒƒãƒˆæŠ½å‡ºï¼ˆãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼‰')
            return self._get_demo_snippets(domains)

        except Exception as e:
            logger.warning(f'ã‚¹ãƒ‹ãƒšãƒƒãƒˆæŠ½å‡ºå¤±æ•—: {str(e)}')
            return []

    def _get_demo_snippets(self, domains: list) -> list:
        """ãƒ‡ãƒ¢ç”¨ã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼ˆå®Ÿéš›ã®æ¤œç´¢çµæœã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰"""
        demo_snippets = [
            f"{domains[0]}: RWAå¸‚å ´ã®æ€¥é€Ÿãªæ©Ÿé–¢åŒ–ã«ã‚ˆã‚Šã€BlackRockã¨Franklin TempletonãŒç›¸æ¬¡ã„ã§å¤§å‹ãƒ•ã‚¡ãƒ³ãƒ‰ã‚’è¨­ç«‹ã€‚è¦åˆ¶æ˜ç¢ºåŒ–ã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯ä½ä¸‹ãŒèƒŒæ™¯ã€‚",
            f"{domains[1]}: Ondo Finance ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æ‹¡å¤§ã«ã‚ˆã‚Šã€USDYï¼ˆåˆ©å›ã‚Šä»˜ããƒˆãƒ¼ã‚¯ãƒ³åŒ–ç±³å›½å‚µï¼‰ãŒAPACåœ°åŸŸã§ã®æ¡ç”¨ã‚’åŠ é€Ÿã€‚æ©Ÿé–¢æŠ•è³‡å®¶ã®å‚å…¥ãŒç¶šãã€‚",
            f"{domains[2]}: XDC Networkã€ICCï¼ˆå›½éš›å•†æ¥­ä¼šè­°æ‰€ï¼‰ã¨ã®è²¿æ˜“é‡‘èé€£æºã«ã‚ˆã‚Šã€ä¼æ¥­å‘ã‘ã‚ªãƒ³ãƒã‚§ãƒ¼ãƒ³æ±ºæ¸ˆã®å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚ºã«ç§»è¡Œã€‚æ—¥æœ¬ã®å¤§æ‰‹å•†ç¤¾ã‚‚å‚å…¥æ¤œè¨ã€‚",
            f"{domains[3]}: Centrifugeã€æ©Ÿé–¢å‘ã‘ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãƒ—ãƒ¼ãƒ«ã®æ§‹ç¯‰ã«ã‚ˆã‚Šã€æ•°åå„„ãƒ‰ãƒ«è¦æ¨¡ã®ä¼æ¥­èè³‡ãŒDeFiã§å®Ÿç¾å¯èƒ½ã«ã€‚",
            f"{domains[0]}: æ—¥æœ¬é‡‘èåºã€RWAã‚»ã‚¯ã‚¿ãƒ¼ã®è¦åˆ¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ­£å¼æ‰¿èªã€‚ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ãƒ¼åŒ–è³‡ç”£ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãŒæ€¥åŠ é€Ÿã™ã‚‹è¦‹é€šã—ã€‚",
        ]
        return demo_snippets[:min(5, len(demo_snippets))]

    def _get_demo_news_data(self) -> dict:
        """ãƒ‡ãƒ¢ç”¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿"""
        return {
            'query': 'RWA Market Update',
            'domains': config.TARGET_DOMAINS[:4] if config else [],
            'snippets': [
                'BlackRockã¨Franklin TempletonãŒç›¸æ¬¡ã„ã§å¤§å‹RWAãƒ•ã‚¡ãƒ³ãƒ‰ã‚’è¨­ç«‹ã—ã€æ©Ÿé–¢ãƒãƒãƒ¼ã®æµå…¥ãŒåŠ é€Ÿã€‚',
                'Ondo Finance ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æ‹¡å¤§ã«ã‚ˆã‚Šã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ç±³å›½å‚µï¼ˆUSDYï¼‰ã®æ¡ç”¨ãŒæ€¥æ‹¡å¤§ã€‚',
                'XDC Network ã¨ ICC ã®ææºã«ã‚ˆã‚Šã€ä¼æ¥­å‘ã‘ã‚ªãƒ³ãƒã‚§ãƒ¼ãƒ³æ±ºæ¸ˆãŒå®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚ºã¸ã€‚',
                'Centrifuge ã®æ©Ÿé–¢å‘ã‘ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãƒ—ãƒ¼ãƒ«æ§‹ç¯‰ã§ã€ä¼æ¥­èè³‡ã®DeFiåŒ–ãŒå‰é€²ã€‚',
                'æ—¥æœ¬é‡‘èåºãŒRWAè¦åˆ¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ­£å¼æ‰¿èªã—ã€å›½å†…ã¸ã®æ³¢åŠåŠ¹æœã«æœŸå¾…ã€‚',
            ],
            'status': 'demo'
        }

    def _build_macro_context(self) -> str:
        """rwa_context.py ã‹ã‚‰ ãƒã‚¯ãƒ­æ–‡è„ˆã‚’æŠ½å‡ºã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ„ã¿è¾¼ã‚ã‚‹å½¢å¼ã«å¤‰æ›"""
        if not rwa_context:
            return ""

        import random

        # ãƒ©ãƒ³ãƒ€ãƒ ã«10é …ç›®ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆAI ã®ç†è§£ã‚’åŠ©ã‘ã‚‹ãŸã‚ï¼‰
        sample_news = random.sample(
            rwa_context.MACRO_CONTEXT_NEWS,
            min(10, len(rwa_context.MACRO_CONTEXT_NEWS))
        )

        context_parts = [
            "ã€RWAå¸‚å ´ã®æ­´å²çš„ãƒã‚¯ãƒ­æ–‡è„ˆ - éå»ã®é‡è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»äº‹ä¾‹ï¼ˆå‚è€ƒï¼‰ã€‘",
            "ä»¥ä¸‹ã¯ã€RWAå¸‚å ´ãŒæ©Ÿé–¢åŒ–ã—ã¦ã„ãéç¨‹ã§å®Ÿéš›ã«èµ·ããŸé‡è¦ãªå‡ºæ¥äº‹ã‚„è¦åˆ¶æ•´å‚™ã§ã™ã€‚",
            "ã“ã‚Œã‚‰ã®æ–‡è„ˆã‚’è¸ã¾ãˆã€æœ¬æ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã€ãªãœé‡è¦ã‹ã€ã€ã©ã‚“ãªèƒŒæ™¯ãŒã‚ã‚‹ã®ã‹ã€ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
            ""
        ]

        for i, news_item in enumerate(sample_news, 1):
            context_parts.append(f"  {i}. {news_item}")

        return "\n".join(context_parts)

    def generate_nanobanana_image(self, prompt: str, image_type: str) -> str:
        """Nanobanana API ã§ç”»åƒã‚’ç”Ÿæˆ"""
        try:
            if not self.nanobanana_key:
                logger.warning('Nanobanana API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”»åƒã‚’ä½¿ç”¨ã—ã¾ã™')
                return self._get_fallback_image_url(image_type)

            logger.info(f'Nanobanana ã§ç”»åƒã‚’ç”Ÿæˆä¸­: {image_type}')

            url = 'https://api.nanobanana.net/api/v1/generate'
            headers = {
                'Authorization': f'Bearer {self.nanobanana_key}',
                'Content-Type': 'application/json'
            }

            payload = {
                'prompt': prompt,
                'model': 'anime',  # ã¾ãŸã¯ 'realistic'
                'width': 1024,
                'height': 576,
                'num_inference_steps': 20,
                'guidance_scale': 7.5
            }

            response = requests.post(url, json=payload, headers=headers, timeout=30)

            if response.status_code == 200:
                data = response.json()
                if 'images' in data and len(data['images']) > 0:
                    image_url = data['images'][0]
                    logger.info(f'âœ… Nanobanana ç”»åƒç”ŸæˆæˆåŠŸ: {image_type}')
                    return image_url
            else:
                logger.warning(f'Nanobanana API ã‚¨ãƒ©ãƒ¼: {response.status_code}')

        except Exception as e:
            logger.warning(f'Nanobanana ç”»åƒç”Ÿæˆå¤±æ•—: {str(e)[:50]}')

        return self._get_fallback_image_url(image_type)

    def fetch_twitter_sentiment(self) -> dict:
        """Xï¼ˆTwitterï¼‰ã‹ã‚‰ RWA é–¢é€£ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å–å¾—ã—ã¦ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ"""
        try:
            if not self.twitter_bearer_token or not tweepy:
                logger.warning('Twitter API ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™')
                return self._get_demo_sentiment_data()

            logger.info('Xï¼ˆTwitterï¼‰ã‹ã‚‰ RWA é–¢é€£ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å–å¾—ä¸­...')

            # Tweepy ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
            client = tweepy.Client(bearer_token=self.twitter_bearer_token)

            # RWA é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
            keywords = ['ONDO', 'XDC', 'RWA', 'tokenized assets']
            all_tweets = []

            for keyword in keywords:
                try:
                    query = f'{keyword} -is:retweet lang:ja'
                    tweets = client.search_recent_tweets(
                        query=query,
                        max_results=10,
                        tweet_fields=['public_metrics', 'created_at']
                    )

                    if tweets.data:
                        for tweet in tweets.data:
                            all_tweets.append({
                                'keyword': keyword,
                                'text': tweet.text,
                                'likes': tweet.public_metrics['like_count'],
                                'retweets': tweet.public_metrics['retweet_count']
                            })

                except Exception as e:
                    logger.warning(f'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ "{keyword}" ã®æ¤œç´¢å¤±æ•—: {str(e)[:50]}')

            # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ
            if all_tweets and self.sentiment_analyzer:
                sentiment_results = self._analyze_sentiment(all_tweets)
                return sentiment_results
            else:
                return self._get_demo_sentiment_data()

        except Exception as e:
            logger.warning(f'Twitter ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {str(e)[:100]}')
            return self._get_demo_sentiment_data()

    def _analyze_sentiment(self, tweets: list) -> dict:
        """ãƒ„ã‚¤ãƒ¼ãƒˆã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ"""
        try:
            if not self.sentiment_analyzer:
                return self._get_demo_sentiment_data()

            positive = 0
            negative = 0
            neutral = 0
            top_tweets = []

            for tweet in tweets:
                scores = self.sentiment_analyzer.polarity_scores(tweet['text'])
                sentiment = scores['compound']

                # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†é¡
                if sentiment > 0.05:
                    positive += 1
                    sentiment_label = 'ãƒã‚¸ãƒ†ã‚£ãƒ–'
                elif sentiment < -0.05:
                    negative += 1
                    sentiment_label = 'ãƒã‚¬ãƒ†ã‚£ãƒ–'
                else:
                    neutral += 1
                    sentiment_label = 'ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«'

                top_tweets.append({
                    'text': tweet['text'][:150],
                    'keyword': tweet['keyword'],
                    'sentiment': sentiment_label,
                    'score': round(sentiment, 2),
                    'engagement': tweet['likes'] + tweet['retweets']
                })

            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆé †ã§ã‚½ãƒ¼ãƒˆ
            top_tweets = sorted(top_tweets, key=lambda x: x['engagement'], reverse=True)[:5]

            total = len(tweets)

            return {
                'total_tweets': total,
                'sentiment': {
                    'positive': {'count': positive, 'percentage': round(positive / total * 100, 1) if total > 0 else 0},
                    'negative': {'count': negative, 'percentage': round(negative / total * 100, 1) if total > 0 else 0},
                    'neutral': {'count': neutral, 'percentage': round(neutral / total * 100, 1) if total > 0 else 0}
                },
                'top_tweets': top_tweets,
                'status': 'success'
            }

        except Exception as e:
            logger.warning(f'ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æå¤±æ•—: {str(e)[:50]}')
            return self._get_demo_sentiment_data()

    def _get_demo_sentiment_data(self) -> dict:
        """ãƒ‡ãƒ¢ç”¨ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æãƒ‡ãƒ¼ã‚¿"""
        return {
            'total_tweets': 50,
            'sentiment': {
                'positive': {'count': 30, 'percentage': 60.0},
                'negative': {'count': 10, 'percentage': 20.0},
                'neutral': {'count': 10, 'percentage': 20.0}
            },
            'top_tweets': [
                {'text': 'ğŸš€ ONDO ãƒˆãƒ¼ã‚¯ãƒ³ãŒæ€¥ä¸Šæ˜‡ï¼æ©Ÿé–¢æŠ•è³‡å®¶ã®è²·ã„ãŒå§‹ã¾ã£ãŸ', 'keyword': 'ONDO', 'sentiment': 'ãƒã‚¸ãƒ†ã‚£ãƒ–', 'score': 0.85, 'engagement': 2500},
                {'text': 'RWA ã‚»ã‚¯ã‚¿ãƒ¼ã€SEC ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ç™ºè¡¨ã§è¦åˆ¶ãƒªã‚¹ã‚¯ä½ä¸‹', 'keyword': 'RWA', 'sentiment': 'ãƒã‚¸ãƒ†ã‚£ãƒ–', 'score': 0.72, 'engagement': 1800},
                {'text': 'XDC ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ±å—ã‚¢ã‚¸ã‚¢å±•é–‹ãŒæœ¬æ ¼åŒ–', 'keyword': 'XDC', 'sentiment': 'ãƒã‚¸ãƒ†ã‚£ãƒ–', 'score': 0.68, 'engagement': 1200},
                {'text': 'Tokenized assets ã®å¸‚å ´è¦æ¨¡ã€ä»Šå¹´ä¸­ã«2å€ã«', 'keyword': 'tokenized assets', 'sentiment': 'ãƒã‚¸ãƒ†ã‚£ãƒ–', 'score': 0.75, 'engagement': 980},
                {'text': 'RWA å¸‚å ´ã®æµå‹•æ€§ãŒæ€¥é€Ÿã«æ”¹å–„ä¸­', 'keyword': 'RWA', 'sentiment': 'ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«', 'score': 0.15, 'engagement': 650}
            ],
            'status': 'demo'
        }

    def _get_fallback_image_url(self, image_type: str) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”»åƒ URL ã‚’è¿”ã™"""
        fallback_urls = {
            'trend_analysis': 'https://via.placeholder.com/1024x576?text=Google+Trends+Analysis',
            'investment_strategy': 'https://via.placeholder.com/1024x576?text=Investment+Strategy',
            'market_outlook': 'https://via.placeholder.com/1024x576?text=Market+Outlook'
        }
        return fallback_urls.get(image_type, fallback_urls['trend_analysis'])

    def _get_default_article(self) -> str:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨˜äº‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ™ãƒ¼ã‚¹ã€2000æ–‡å­—å‰å¾Œï¼‰"""
        return """
<h2>RWAå¸‚å ´ãŒæ©Ÿé–¢åŒ–ãƒ•ã‚§ãƒ¼ã‚ºã¸ - è¦åˆ¶æ•´å‚™ã¨åˆ¶åº¦çš„å—å®¹ã®é€²å±•</h2>

<p>
Real World Assetsï¼ˆRWAï¼‰ã‚»ã‚¯ã‚¿ãƒ¼ã¯2024ï½2025å¹´ã‚’é€šã˜ã¦ã€
åˆ¶åº¦çš„ãªåŸºç›¤æ•´å‚™ãŒæ€¥é€Ÿã«é€²ã‚€å±€é¢ã«å…¥ã£ã¦ã„ã¾ã™ã€‚
å¾“æ¥ã®å€‹äººæŠ•è³‡å®¶ä¸»å°ã®å¸‚å ´ã‹ã‚‰ã€å¤§å‹æ©Ÿé–¢ã«ã‚ˆã‚‹è³‡ç”£ã‚¯ãƒ©ã‚¹ã¨ã—ã¦ã®èªè­˜ã¸ã¨æ®µéšçš„ã«ç§»è¡Œã—ã¦ã„ã¾ã™ã€‚
æœ¬è¨˜äº‹ã§ã¯ã€ä¾¡æ ¼äºˆæ¸¬ã§ã¯ãªãã€RWAå¸‚å ´ã‚’æ”¯ãˆã‚‹æ§‹é€ çš„ãªå¤‰åŒ–ã‚’åˆ†æã—ã¾ã™ã€‚
</p>

<h2>æ©Ÿé–¢æŠ•è³‡å®¶å‚å…¥ã®å®Ÿä¾‹</h2>

<p>
<strong>BlackRock</strong> ãªã©ã®å¤§æ‰‹è³‡ç”£é‹ç”¨ä¼šç¤¾ãŒã€å…¬å¼ãª RWA æŠ•è³‡ãƒ•ã‚¡ãƒ³ãƒ‰ã®çµ„æˆã‚’ç™ºè¡¨ã—ã¦ã„ã¾ã™ã€‚
ã“ã‚Œã¯å˜ãªã‚‹ã€Œæ–°ã—ã„æŠ•è³‡ãƒ†ãƒ¼ãƒã€ã§ã¯ãªãã€å¾“æ¥ã® TradFiï¼ˆä¼çµ±é‡‘èï¼‰æ©Ÿé–¢ã«ã‚ˆã‚‹
ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³è³‡ç”£ã¸ã®æœ¬æ ¼çš„ãªå—ã‘å…¥ã‚Œã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚
</p>

<ul>
  <li>Franklin Templeton: RWA ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ•ã‚¡ãƒ³ãƒ‰ã®çµ„æˆ</li>
  <li>JPMorgan: ä¼æ¥­å‚µã®ã‚ªãƒ³ãƒã‚§ãƒ¼ãƒ³ç™ºè¡Œè©¦é¨“</li>
  <li>Fidelity: RWA ãƒ•ã‚¡ãƒ³ãƒ‰ã®æ©Ÿé–¢å‘ã‘ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆé–‹ç™º</li>
</ul>

<h2>è¦åˆ¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æ•´å‚™é€²å±•</h2>

<p>
SECï¼ˆç±³å›½è¨¼åˆ¸å–å¼•å§”å“¡ä¼šï¼‰ã¨é‡‘èåºï¼ˆæ—¥æœ¬ï¼‰ã‚’å«ã‚€ä¸–ç•Œã®é‡‘èç›£ç£å½“å±€ãŒã€
RWA ã¨è¨¼åˆ¸ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã«é–¢ã™ã‚‹æ˜ç¢ºãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’ç›¸æ¬¡ã„ã§ç™ºè¡¨ã—ã¦ã„ã¾ã™ã€‚
ã“ã‚Œã¾ã§ã®ã€Œã‚°ãƒ¬ãƒ¼ã‚¾ãƒ¼ãƒ³ã€ã‹ã‚‰ã€Œæ˜ç¢ºãªè¦åˆ¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ã¸ã®è»¢æ›ã§ã™ã€‚
</p>

<p>
<strong>ä¸»è¦ãªè¦åˆ¶å‹•å‘ï¼š</strong>
</p>

<ul>
  <li>SEC: ã€ŒTreasury Tokenizationã€ã®æ¡ä»¶ä»˜ãå®¹èª</li>
  <li>æ—¥æœ¬ é‡‘èåº: RWA ã‚»ã‚¯ã‚¿ãƒ¼ã®ä½ç½®ã¥ã‘ã‚’æ­£å¼ã«æ˜ç¢ºåŒ–</li>
  <li>Singapore MAS: STOï¼ˆSecurity Token Offeringï¼‰ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æ çµ„ã¿ã®æ•´å‚™</li>
  <li>EU: MiCAï¼ˆMarkets in Crypto-assets Regulationï¼‰ã«ã‚ˆã‚‹è¦åˆ¶çµ±ä¸€</li>
</ul>

<h2>æŠ€è¡“ã‚¤ãƒ³ãƒ•ãƒ©ã®æˆç†Ÿ</h2>

<p>
RWA ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ”¯ãˆã‚‹ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³åŸºç›¤æŠ€è¡“ã¯ã€
ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ç›¸äº’é‹ç”¨æ€§ã®é¢ã§å¤§ããé€²åŒ–ã—ã¦ã„ã¾ã™ã€‚
</p>

<ul>
  <li><strong>Chainlinkï¼ˆLINKï¼‰</strong>: RWA ãƒ‡ãƒ¼ã‚¿ä¾›çµ¦ã®åŸºç›¤ã¨ã—ã¦ã®åœ°ä½ç¢ºç«‹</li>
  <li><strong>Avalancheï¼ˆAVAXï¼‰</strong>: ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå‘ã‘ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </li>
  <li><strong>Polymeshï¼ˆPOLYXï¼‰</strong>: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒˆãƒ¼ã‚¯ãƒ³å°‚ç”¨ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³</li>
</ul>

<h2>RWAå³é¸50éŠ˜æŸ„ã®åˆ†é¡çš„ç†è§£</h2>

<p>
RWA ã‚»ã‚¯ã‚¿ãƒ¼ã¯å˜ä¸€ã®å¸‚å ´ã§ã¯ãªãã€è¤‡æ•°ã®ã‚µãƒ–ã‚»ã‚¯ã‚¿ãƒ¼ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ï¼š
</p>

<ul>
  <li><strong>ã‚¤ãƒ³ãƒ•ãƒ©å±¤</strong>: XDC Networkã€Chainlinkã€Avalanche ãªã©åŸºç›¤æŠ€è¡“</li>
  <li><strong>è¨¼åˆ¸ãƒ»å›½å‚µ</strong>: Ondo Financeã€Centrifuge ãªã©æ©Ÿé–¢å‘ã‘å•†å“</li>
  <li><strong>ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ</strong>: Maple Financeã€Goldfinch ãªã©èè³‡ãƒ—ãƒ­ãƒˆã‚³ãƒ«</li>
  <li><strong>ä¸å‹•ç”£ãƒ»ç‰©ç†è³‡ç”£</strong>: åœŸåœ°æ‰€æœ‰æ¨©ã€ä¸å‹•ç”£ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹</li>
  <li><strong>ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£</strong>: é‡‘ç¾ç‰©ãƒšãƒƒã‚°ã€ã‚«ãƒ¼ãƒœãƒ³ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ</li>
</ul>

<h2>é•·æœŸæŠ•è³‡å®¶è¦–ç‚¹ã§ã®è©•ä¾¡è»¸</h2>

<p>
RWA ã‚»ã‚¯ã‚¿ãƒ¼ã¸ã®æŠ•è³‡åˆ¤æ–­ã¯ã€ä»¥ä¸‹ã® 5 ã¤ã®åŸºè»¸ã§è¡Œã†ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ï¼š
</p>

<ol>
  <li><strong>æ©Ÿé–¢æŠ•è³‡å®¶å‚å…¥åº¦ï¼ˆ25%ï¼‰</strong>: è³‡ç”£è¦æ¨¡ã®å¢—åŠ ã€ãƒ•ã‚¡ãƒ³ãƒ‰çµ„æˆæ•°</li>
  <li><strong>è¦åˆ¶æ˜ç¢ºæ€§ï¼ˆ25%ï¼‰</strong>: ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ç™ºè¡¨ã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å–å¾—</li>
  <li><strong>æŠ€è¡“çš„æˆç†Ÿåº¦ï¼ˆ20%ï¼‰</strong>: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£</li>
  <li><strong>ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ææºï¼ˆ15%ï¼‰</strong>: TradFi ã¨ã®çµ±åˆã€å®Ÿè£…ä¼æ¥­æ•°</li>
  <li><strong>å¸‚å ´è¦æ¨¡æˆé•·ï¼ˆ15%ï¼‰</strong>: å–å¼•é«˜å¢—åŠ ã€æ–°è¦å‚å…¥è€…æ•°</li>
</ol>

<h2>ãƒªã‚¹ã‚¯è¦å› ã®å®šæ€§çš„è©•ä¾¡</h2>

<ul>
  <li>è¦åˆ¶æ–¹é‡ã®æ€¥å¤‰å‹•ï¼ˆä½ç¢ºåº¦ã ãŒå½±éŸ¿åº¦ãŒé«˜ã„ï¼‰</li>
  <li>æŠ€è¡“çš„è„†å¼±æ€§ã®ç™ºè¦‹ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ç¶™ç¶šä¸­ï¼‰</li>
  <li>ãƒã‚¯ãƒ­é‡‘èç’°å¢ƒã®å¤‰åŒ–ï¼ˆåˆ©ä¸Šã’ãƒ»é‡‘åˆ©ä½ä¸‹ã®å½±éŸ¿ï¼‰</li>
  <li>å¤§æ‰‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å¤±æ•—äº‹ä¾‹ï¼ˆå¸‚å ´å¿ƒç†ã¸ã®æ‚ªå½±éŸ¿ï¼‰</li>
</ul>

<h2>çµè«–ï¼šæ§‹é€ çš„ãƒˆãƒ¬ãƒ³ãƒ‰ vs. çŸ­æœŸå¤‰å‹•</h2>

<p>
RWA ã‚»ã‚¯ã‚¿ãƒ¼ã®é•·æœŸçš„ãªæˆé•·è»Œé“ã¯ã€ä»¥ä¸‹ã®ç†ç”±ã§å …ç‰¢ã§ã™ï¼š
</p>

<ul>
  <li>TradFi ã‹ã‚‰ã®å¿…ç„¶çš„ãªæµå…¥ï¼ˆæ—¢å¾—æ¨©ç›Šã®å†æ§‹ç¯‰ï¼‰</li>
  <li>è¦åˆ¶å½“å±€ã®ä¸€è²«ã—ãŸå§¿å‹¢ï¼ˆã‚µãƒãƒ¼ãƒ†ã‚£ãƒ–ï¼‰</li>
  <li>æŠ€è¡“çš„å®Ÿè£…ã®åŠ é€Ÿï¼ˆã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£å®Ÿç¾ï¼‰</li>
  <li>æ©Ÿé–¢æŠ•è³‡å®¶ã®å‚å…¥ç¶™ç¶šï¼ˆè³‡ç”£é…åˆ†ã®å¤šæ§˜åŒ–ï¼‰</li>
</ul>

<p>
ä¸€æ–¹ã§ã€çŸ­æœŸçš„ãªä¾¡æ ¼å¤‰å‹•ã«ã¯å¸¸ã«ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒä¼´ã„ã¾ã™ã€‚
é•·æœŸä¿æœ‰ã‚¤ãƒ³ãƒ™ã‚¹ã‚¿ãƒ¼ã¯ã€çŸ­æœŸçš„ãªãƒã‚¤ã‚ºã‚’ç„¡è¦–ã—ã€
æ§‹é€ çš„ãªãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºæ”¹å–„ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚
</p>

<p style="color: #667eea; font-weight: bold; font-size: 1.1em; margin-top: 20px;">
æœ¬åˆ†æã¯æŠ•è³‡åˆ¤æ–­ã®å‚è€ƒæƒ…å ±ã§ã™ã€‚æŠ•è³‡æ¨å¥¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
å€‹äººã®è²¬ä»»ã¨é¢¨é™©ç®¡ç†ã®ä¸‹ã§åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
</p>
"""

    def generate_html_page(self, article_title: str, article_content: str,
                          image_paths: list = None, sentiment_data: dict = None) -> str:
        """HTML ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆï¼ˆGitHub Pages ç”¨ + ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æï¼‰"""
        try:
            logger.info('HTML ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆä¸­...')

            if image_paths is None:
                image_paths = []

            if sentiment_data is None:
                sentiment_data = self._get_demo_sentiment_data()

            # ç”»åƒURL ã‚’ä¿å­˜ï¼ˆè¨˜äº‹å†…ã«åŸ‹ã‚è¾¼ã‚€ï¼‰
            image_urls_list = image_paths if image_paths else []

            # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ HTML ã‚’ç”Ÿæˆ
            sentiment_html = self._generate_sentiment_html(sentiment_data)

            # HTML ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
            html_template = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{article_title}</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}

        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Hiragino Kaku Gothic ProN', 'Yu Gothic', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 15px;
            line-height: 1.8;
            color: #333;
        }}

        .container {{
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
            overflow: hidden;
        }}

        header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px 20px;
            text-align: center;
        }}

        header h1 {{
            font-size: 1.8em;
            margin-bottom: 10px;
            font-weight: 700;
            word-wrap: break-word;
        }}

        .timestamp {{
            opacity: 0.9;
            font-size: 0.95em;
        }}

        .author {{
            color: #fff;
            font-size: 0.9em;
            margin-top: 15px;
            opacity: 0.95;
        }}

        article {{
            padding: 30px 20px;
        }}

        article h2 {{
            color: #667eea;
            font-size: 1.4em;
            margin-top: 30px;
            margin-bottom: 15px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }}

        article h2:first-of-type {{
            margin-top: 0;
        }}

        article p {{
            margin-bottom: 15px;
            line-height: 1.8;
        }}

        article ul, article ol {{
            margin-left: 25px;
            margin-bottom: 15px;
        }}

        article li {{
            margin-bottom: 10px;
        }}

        .article-image {{
            width: 100%;
            max-width: 100%;
            height: auto;
            margin: 30px 0;
            border-radius: 10px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }}

        .sources {{
            background: #f5f5f5;
            padding: 20px;
            border-radius: 10px;
            margin-top: 30px;
        }}

        .sources h3 {{
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.1em;
        }}

        .sources ol {{
            margin-left: 20px;
        }}

        .sources li {{
            margin-bottom: 10px;
            font-size: 0.95em;
        }}

        .sources a {{
            color: #667eea;
            text-decoration: none;
            word-break: break-all;
        }}

        .sources a:hover {{
            text-decoration: underline;
        }}

        footer {{
            background: #f5f5f5;
            padding: 20px;
            text-align: center;
            font-size: 0.9em;
            color: #666;
            border-top: 1px solid #ddd;
        }}

        .footer-note {{
            margin-top: 10px;
            font-size: 0.85em;
        }}

        @media (max-width: 600px) {{
            body {{
                padding: 10px;
            }}

            header {{
                padding: 25px 15px;
            }}

            header h1 {{
                font-size: 1.4em;
            }}

            article {{
                padding: 20px 15px;
            }}

            article h2 {{
                font-size: 1.2em;
            }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸš€ {article_title}</h1>
            <div class="timestamp">ğŸ“… {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S (JST)')}</div>
            <div class="author">ğŸ“ xdc.masterï¼ˆä¸å‹•ç”£é‹å–¶ Ã— XDCé•·æœŸä¿æœ‰ã‚¤ãƒ³ãƒ™ã‚¹ã‚¿ãƒ¼ï¼‰</div>
        </header>

        <article>
            {images_html}
            {article_content}
        </article>

        <div class="sources">
            <h3>ğŸ“š å‚è€ƒè³‡æ–™ãƒ»å‚ç…§å…ƒ</h3>
            <ol>
                <li><a href="https://cointelegraph.jp" target="_blank">Coin Telegraph</a> - ãƒ‹ãƒ¥ãƒ¼ã‚¹</li>
                <li><a href="https://www.theblock.co" target="_blank">The Block</a> - ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³åˆ†æ</li>
                <li><a href="https://www.coindesk.com" target="_blank">CoinDesk</a> - ãƒ‹ãƒ¥ãƒ¼ã‚¹</li>
                <li><a href="https://messari.io" target="_blank">Messari</a> - ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹</li>
                <li><a href="https://glassnode.com" target="_blank">Glassnode</a> - ã‚ªãƒ³ãƒã‚§ãƒ¼ãƒ³åˆ†æ</li>
                <li><a href="https://tokenterminal.com" target="_blank">Token Terminal</a> - ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³åˆ†æ</li>
                <li><a href="https://chain.link/ja" target="_blank">Chainlink</a> - ã‚ªãƒ©ã‚¯ãƒ«</li>
                <li><a href="https://www.fsa.go.jp" target="_blank">é‡‘èåº</a> - ä»®æƒ³è³‡ç”£é–¢é€£æ”¿ç­–</li>
            </ol>
        </div>

        <footer>
            <p>ğŸŒ RWA News Dashboard - GitHub Pages Auto-Published</p>
            <p class="footer-note">æœ¬è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã™ã€‚æŠ•è³‡åˆ¤æ–­ã®å‚è€ƒæƒ…å ±ã§ã‚ã‚Šã€æŠ•è³‡æ¨å¥¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</p>
        </footer>
    </div>
</body>
</html>"""

            # index.html ã¨ã—ã¦ä¿å­˜
            output_dir = Path('docs')
            output_dir.mkdir(exist_ok=True)
            html_file = output_dir / 'index.html'

            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_template)

            logger.info(f'âœ… HTML ãƒšãƒ¼ã‚¸ç”Ÿæˆ: {html_file}')
            return str(html_file)

        except Exception as e:
            logger.error(f'HTML ç”Ÿæˆå¤±æ•—: {str(e)}')
            return None

    async def run(self):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        try:
            logger.info('=' * 60)
            logger.info('RWA ãƒ‹ãƒ¥ãƒ¼ã‚¹è‡ªå‹•å…¬é–‹ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ï¼ˆv4.0 - GitHub Pagesï¼‰')
            logger.info('å®Ÿè¡Œæ™‚åˆ»: ' + datetime.now().strftime('%Y-%m-%dT%H:%M:%S'))
            logger.info('=' * 60)

            # ã‚¹ãƒ†ãƒƒãƒ— 1: ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—
            trends_data = await self.fetch_trends()

            # ã‚¹ãƒ†ãƒƒãƒ— 2: ä»®æƒ³è³‡ç”£ãƒ‡ãƒ¼ã‚¿å–å¾—
            coingecko_data = await self.fetch_coingecko_data()

            # ã‚¹ãƒ†ãƒƒãƒ— 2.5: Xï¼ˆTwitterï¼‰ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ
            logger.info('\nXï¼ˆTwitterï¼‰ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æä¸­...')
            sentiment_data = self.fetch_twitter_sentiment()

            # ã‚¹ãƒ†ãƒƒãƒ— 3: ç”»åƒç”Ÿæˆï¼ˆNanobanana + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            logger.info('\nç”»åƒã‚’ç”Ÿæˆä¸­...')
            image_urls = [
                self.generate_nanobanana_image(
                    'RWA institutional adoption roadmap, regulatory framework development, central bank digital currency integration, professional infographic, blue and purple gradient',
                    'trend_analysis'
                ),
                self.generate_nanobanana_image(
                    'Real World Assets ecosystem diagram, blockchain infrastructure connecting TradFi institutions, tokenization layers, technical architecture, modern design',
                    'investment_strategy'
                ),
                self.generate_nanobanana_image(
                    'Global RWA market structure, asset classes taxonomy, insurance, treasury bonds, real estate, commodities, professional financial illustration',
                    'market_outlook'
                )
            ]

            # ã‚¹ãƒ†ãƒƒãƒ— 4: AI è¨˜äº‹ç”Ÿæˆ
            article_content = self.generate_news_article(trends_data)

            if not article_content:
                logger.error('è¨˜äº‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ')
                return False

            # ã‚¹ãƒ†ãƒƒãƒ— 5: HTML ãƒšãƒ¼ã‚¸ç”Ÿæˆï¼ˆç”»åƒ3æšåŸ‹ã‚è¾¼ã¿ + ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æï¼‰
            article_title = 'RWAå¸‚å ´ã®æ©Ÿé–¢åŒ–ã¨è¦åˆ¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ•´å‚™çŠ¶æ³'
            html_file = self.generate_html_page(
                article_title,
                article_content,
                image_urls,
                sentiment_data
            )

            if html_file:
                logger.info('\n' + '=' * 60)
                logger.info('âœ… HTML ãƒšãƒ¼ã‚¸ç”ŸæˆæˆåŠŸï¼')
                logger.info('=' * 60)
                logger.info(f'ãƒ•ã‚¡ã‚¤ãƒ«: {html_file}')
                logger.info('\nğŸ“¡ GitHub Pages ã«è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã¾ã™')
                return True
            else:
                logger.error('HTML ç”Ÿæˆå¤±æ•—')
                return False

        except Exception as e:
            logger.error(f'ã‚¨ãƒ©ãƒ¼: {str(e)}')
            import traceback
            traceback.print_exc()
            return False


async def main():
    """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    generator = RWANewsGenerator()
    success = await generator.run()
    return success


if __name__ == '__main__':
    import asyncio
    success = asyncio.run(main())
    exit(0 if success else 1)

    def _generate_sentiment_html(self, sentiment_data: dict) -> str:
        """ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æçµæœã‚’ HTML ã§ç”Ÿæˆ"""
        try:
            if not sentiment_data:
                return ""

            positive = sentiment_data.get('sentiment', {}).get('positive', {})
            negative = sentiment_data.get('sentiment', {}).get('negative', {})
            neutral = sentiment_data.get('sentiment', {}).get('neutral', {})

            top_tweets_html = ""
            for i, tweet in enumerate(sentiment_data.get('top_tweets', [])[:5], 1):
                sentiment_color = '#4caf50' if tweet['sentiment'] == 'ãƒã‚¸ãƒ†ã‚£ãƒ–' else '#ff9800' if tweet['sentiment'] == 'ãƒã‚¬ãƒ†ã‚£ãƒ–' else '#2196f3'
                top_tweets_html += f"""<div style="background: #f9f9f9; padding: 15px; border-radius: 8px; margin-bottom: 10px; border-left: 4px solid {sentiment_color};">
                    <div style="font-weight: bold; color: {sentiment_color};">{i}. [{tweet['keyword']}] {tweet['sentiment']}</div>
                    <div style="color: #666; margin: 10px 0;">{tweet['text']}</div>
                    <div style="color: #999; font-size: 0.9em;">ã‚¹ã‚³ã‚¢: {tweet['score']} | ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ: {tweet['engagement']:,}</div>
                </div>"""

            sentiment_section = f"""<h2>ğŸ“± Xï¼ˆTwitterï¼‰ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ</h2>
<p>Xï¼ˆTwitterï¼‰ä¸Šã® RWA é–¢é€£ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆ{sentiment_data.get('total_tweets', 0)}ä»¶ï¼‰ã‚’åˆ†æã—ã¾ã—ãŸã€‚</p>
<div style="background: #f0f7ff; padding: 20px; border-radius: 10px; margin: 20px 0;">
<h3 style="color: #667eea; margin-bottom: 15px;">ğŸ“Š ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†å¸ƒ</h3>
<div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px;">
<div style="background: white; padding: 15px; border-radius: 8px; text-align: center; border: 2px solid #4caf50;">
<div style="font-size: 2em; color: #4caf50; font-weight: bold;">{positive.get('percentage', 0):.1f}%</div>
<div style="color: #666;">ãƒã‚¸ãƒ†ã‚£ãƒ–</div>
</div>
<div style="background: white; padding: 15px; border-radius: 8px; text-align: center; border: 2px solid #2196f3;">
<div style="font-size: 2em; color: #2196f3; font-weight: bold;">{neutral.get('percentage', 0):.1f}%</div>
<div style="color: #666;">ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«</div>
</div>
<div style="background: white; padding: 15px; border-radius: 8px; text-align: center; border: 2px solid #ff9800;">
<div style="font-size: 2em; color: #ff9800; font-weight: bold;">{negative.get('percentage', 0):.1f}%</div>
<div style="color: #666;">ãƒã‚¬ãƒ†ã‚£ãƒ–</div>
</div>
</div>
</div>
<h3>ğŸ” ãƒˆãƒƒãƒ—ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆé †ï¼‰</h3>
{top_tweets_html}"""

            return sentiment_section

        except Exception as e:
            return ""
